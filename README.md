# ðŸŽ¬ Snapverse

> **Turn YouTube Videos into Stunning Shorts with AI**

Snapverse is an AI-powered short-form video creation platform that lets you generate scripted conversations using LLMs, clone character voices, overlay character images on background videos, and produce ready-to-post shorts â€” all from a single interface.

![Python](https://img.shields.io/badge/Python-3.10+-3776AB?logo=python&logoColor=white)
![Next.js](https://img.shields.io/badge/Next.js-15-black?logo=next.js)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-009688?logo=fastapi)
![LangChain](https://img.shields.io/badge/LangChain-0.3-1C3C3C?logo=langchain)

---

## âœ¨ Features

| Feature                   | Description                                                                                                                         |
| ------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |
| ðŸ¤– **AI Story Generator** | Generate natural two-character conversations on any topic using Llama 3 70B via Groq                                                |
| ðŸŽ™ï¸ **Voice Cloning**      | Clone real voices with [Chatterbox TTS](https://github.com/resemble-ai/chatterbox) â€” each character speaks in a unique cloned voice |
| ðŸŽ¥ **YouTube Downloader** | Download videos, audio, or playlists from YouTube with automatic sub-clipping via yt-dlp                                            |
| ðŸ–¼ï¸ **Character Overlays** | Select character images that are composited onto the final video                                                                    |
| ðŸ“ **Auto Captions**      | AI-generated topic-based titles using few-shot prompting                                                                            |
| ðŸŽžï¸ **Video Processor**    | Composites background video, cloned audio, subtitles, and character images into a final short                                       |
| ðŸŒ **Modern Web UI**      | Next.js 15 frontend with a panel-based editor for a streamlined creative workflow                                                   |

---

## ðŸ—ï¸ Project Structure

```
Snapverse/
â”œâ”€â”€ Backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI server with REST endpoints
â”‚   â”œâ”€â”€ storygenerator.py       # LLM conversation generator (LangChain + Groq)
â”‚   â”œâ”€â”€ voicegenerator.py       # Chatterbox TTS voice cloning
â”‚   â”œâ”€â”€ videogenerator.py       # MoviePy video compositor
â”‚   â”œâ”€â”€ captionGenerator.py     # AI caption/topic generator
â”‚   â”œâ”€â”€ youtube.py              # yt-dlp YouTube downloader with sub-clipping
â”‚   â””â”€â”€ removebg.py             # Background removal utility (rembg)
â”‚
â”œâ”€â”€ Frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ Home/           # Landing page (Hero, Features, Video Carousel)
â”‚   â”‚   â”‚   â”œâ”€â”€ auth/           # Login & Signup pages
â”‚   â”‚   â”‚   â””â”€â”€ generator/      # Main editor workspace
â”‚   â”‚   â”‚       â”œâ”€â”€ Sidebar.tsx
â”‚   â”‚   â”‚       â”œâ”€â”€ ToolOverlay.tsx
â”‚   â”‚   â”‚       â””â”€â”€ panels/
â”‚   â”‚   â”‚           â”œâ”€â”€ StoryPanel/       # AI chat interface for story generation
â”‚   â”‚   â”‚           â”œâ”€â”€ VideoPanel/       # Background video selection
â”‚   â”‚   â”‚           â”œâ”€â”€ VoicesPanel/      # Voice selection
â”‚   â”‚   â”‚           â”œâ”€â”€ CharactersPanel/  # Character image picker
â”‚   â”‚   â”‚           â””â”€â”€ EditingPanel/     # Preview & render final video
â”‚   â”‚   â””â”€â”€ components/         # Shared UI (Navbar, Footer, Button, InputField, SocialAuth)
â”‚   â””â”€â”€ public/
â”‚       â”œâ”€â”€ characters/         # Character images (PNG)
â”‚       â”œâ”€â”€ voices/             # Voice reference audio (WAV)
â”‚       â”œâ”€â”€ videos/             # Background video clips
â”‚       â””â”€â”€ clips/              # Generated output videos
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```

---

## ðŸ”§ Tech Stack

### Backend

- **[FastAPI](https://fastapi.tiangolo.com/)** â€” REST API server
- **[LangChain](https://www.langchain.com/) + [Groq](https://groq.com/)** â€” LLM orchestration with Llama 3 70B
- **[Chatterbox TTS](https://github.com/resemble-ai/chatterbox)** â€” Zero-shot voice cloning
- **[MoviePy](https://zulko.github.io/moviepy/)** â€” Video editing & compositing
- **[yt-dlp](https://github.com/yt-dlp/yt-dlp)** â€” YouTube downloading
- **[torchaudio](https://pytorch.org/audio/)** â€” Audio processing
- **[FFmpeg](https://ffmpeg.org/)** â€” Media processing backend

### Frontend

- **[Next.js 15](https://nextjs.org/)** â€” React framework (App Router)
- **[TypeScript](https://www.typescriptlang.org/)** â€” Type safety
- **[Tailwind CSS](https://tailwindcss.com/)** â€” Utility-first styling
- **[Heroicons](https://heroicons.com/) + [React Icons](https://react-icons.github.io/react-icons/)** â€” Icons

---

## ðŸš€ Getting Started

### Prerequisites

- **Python 3.10+**
- **Node.js 18+** & **npm**
- **FFmpeg** installed and available in PATH
- **Groq API Key** â€” get one at [console.groq.com](https://console.groq.com/)
- **CUDA GPU** recommended for voice cloning (CPU fallback supported)

### 1. Clone the Repository

```bash
git clone https://github.com/Hashir-Ali-Shah/Snapverse.git
cd Snapverse
```

### 2. Backend Setup

```bash
# Create and activate virtual environment
python -m venv venv
venv\Scripts\activate          # Windows
# source venv/bin/activate     # macOS/Linux

# Install dependencies
pip install -r requirements.txt
pip install fastapi uvicorn moviepy chatterbox-tts rembg pillow torchaudio torch
```

### 3. Set Environment Variable

Set your Groq API key as an environment variable:

**Windows (PowerShell):**

```powershell
$env:GROQ_API_KEY = "your_groq_api_key_here"
```

**Windows (CMD):**

```cmd
set GROQ_API_KEY=your_groq_api_key_here
```

**macOS/Linux:**

```bash
export GROQ_API_KEY="your_groq_api_key_here"
```

### 4. Frontend Setup

```bash
cd Frontend
npm install
```

### 5. Run the Application

**Start the Backend:**

```bash
cd Backend
uvicorn main:app --reload --host 127.0.0.1 --port 8000
```

**Start the Frontend** (in a separate terminal):

```bash
cd Frontend
npm run dev
```

Open **http://localhost:3000** in your browser.

---

## ðŸ“– How It Works

```
1. Story    â†’  2. Video    â†’  3. Characters  â†’  4. Generate
(AI Chat)      (Select BG)    (Pick Two)        (Render MP4)
```

1. **Story Panel** â€” Chat with the AI to generate a two-character conversation on any topic
2. **Video Panel** â€” Pick a background video from the library
3. **Characters Panel** â€” Select two character images (voices are auto-mapped by character name)
4. **Editing Panel** â€” Preview everything, then hit **Generate Video** to:
   - Clone each character's voice with Chatterbox TTS
   - Generate an AI caption/title for the video
   - Composite video + audio + subtitles + character overlays
   - Output a final MP4

---

## ðŸ“¡ API Endpoints

| Method | Endpoint                | Description                                                  |
| ------ | ----------------------- | ------------------------------------------------------------ |
| `POST` | `/generate`             | Generate a two-character conversation from a prompt          |
| `POST` | `/process-conversation` | Render a full video with voice cloning, subtitles & overlays |

### `POST /generate`

```json
// Request
{ "question": "Generate a conversation between Einstein and Newton about gravity" }

// Response
{ "answer": "I've been rethinking gravity...\nBut my laws work perfectly!..." }
```

### `POST /process-conversation`

```json
// Request
{
  "voiceA": "/voices/trump.wav",
  "voiceB": "/voices/obama.wav",
  "conversation": [
    { "id": 1, "speaker": "A", "text": "Hello there!" },
    { "id": 2, "speaker": "B", "text": "Good to see you." }
  ],
  "imageA": "/characters/trump.png",
  "imageB": "/characters/obama.png",
  "video": "/videos/subway_surf.mp4"
}

// Response
{ "message": "Conversation processed successfully", "video_path": "/clips/Topic_Name_uuid.mp4" }
```

---

## ðŸ—‚ï¸ Adding Custom Assets

| Asset       | Format                           | Directory                     |
| ----------- | -------------------------------- | ----------------------------- |
| Characters  | PNG (transparent bg recommended) | `Frontend/public/characters/` |
| Voice refs  | WAV                              | `Frontend/public/voices/`     |
| Backgrounds | MP4                              | `Frontend/public/videos/`     |

> **Note:** Voice files must match their character filename (e.g., `trump.png` â†’ `trump.wav`).

---

## ðŸ‘¥ Authors

- **Hashir Ali Shah** â€” [GitHub](https://github.com/Hashir-Ali-Shah)
